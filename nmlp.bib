@inproceedings{zhu-etal-2025-meaning,
    title = "Meaning Beyond Truth Conditions: Evaluating Discourse Level Understanding via Anaphora Accessibility",
    author = "Zhu, Xiaomeng  and
      Zhou, Zhenghao  and
      Charlow, Simon  and
      Frank, Robert",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.432/",
    doi = "10.18653/v1/2025.acl-long.432",
    pages = "8824--8842",
    ISBN = "979-8-89176-251-0",
    abstract = "We present a hierarchy of natural language understanding abilities and argue for the importance of moving beyond assessments of understanding at the lexical and sentence levels to the discourse level. We propose the task of anaphora accessibility as a diagnostic for assessing discourse understanding, and to this end, present an evaluation dataset inspired by theoretical research in dynamic semantics. We evaluate human and LLM performance on our dataset and find that LLMs and humans align on some tasks and diverge on others. Such divergence can be explained by LLMs' reliance on specific lexical items during language comprehension, in contrast to human sensitivity to structural abstractions."
}
@inproceedings{hou-2020-bridging,
    title = "Bridging Anaphora Resolution as Question Answering",
    author = "Hou, Yufang",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.132/",
    url_arxiv = "https://arxiv.org/abs/2004.07898"
    doi = "10.18653/v1/2020.acl-main.132",
    pages = "1428--1438",
    abstract = "Most previous studies on bridging anaphora resolution (Poesio et al., 2004; Hou et al., 2013b; Hou, 2018a) use the pairwise model to tackle the problem and assume that the gold mention information is given. In this paper, we cast bridging anaphora resolution as question answering based on context. This allows us to find the antecedent for a given anaphor without knowing any gold mention information (except the anaphor itself). We present a question answering framework (BARQA) for this task, which leverages the power of transfer learning. Furthermore, we propose a novel method to generate a large amount of ``quasi-bridging'' training data. We show that our model pre-trained on this dataset and fine-tuned on a small amount of in-domain dataset achieves new state-of-the-art results for bridging anaphora resolution on two bridging corpora (ISNotes (Markert et al., 2012) and BASHI (Ro {\ensuremath{\ddot{}}}siger, 2018))."
}
@inproceedings{he-etal-2025-xcomps,
    title = "{XCOMPS}: A Multilingual Benchmark of Conceptual Minimal Pairs",
    author = "He, Linyang  and
      Nie, Ercong  and
      Dindar, Sukru Samet  and
      Firoozi, Arsalan  and
      Nguyen, Van  and
      Puffay, Corentin  and
      Shimizu, Riki  and
      Ye, Haotian  and
      Brennan, Jonathan  and
      Schmid, Helmut  and
      Sch√ºtze, Hinrich  and
      Mesgarani, Nima",
    editor = "Hahn, Michael  and
      Rani, Priya  and
      Kumar, Ritesh  and
      Shcherbakov, Andreas  and
      Sorokin, Alexey  and
      Serikov, Oleg  and
      Cotterell, Ryan  and
      Vylomova, Ekaterina",
    booktitle = "Proceedings of the 7th Workshop on Research in Computational Linguistic Typology and Multilingual NLP",
    month = aug,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.sigtyp-1.9/",
    doi = "10.18653/v1/2025.sigtyp-1.9",
    pages = "75--81",
    ISBN = "979-8-89176-281-7",
    abstract = "In this work, we introduce XCOMPS, a multilingual conceptual minimal pair dataset that covers 17 languages.Using this dataset, we evaluate LLMs' multilingual conceptual understanding through metalinguistic prompting, direct probability measurement, and neurolinguistic probing. We find that: 1) LLMs exhibit weaker conceptual understanding for low-resource languages, and accuracy varies across languages despite being tested on the same concept sets. 2) LLMs excel at distinguishing concept-property pairs that are visibly different but exhibit a marked performance drop when negative pairs share subtle semantic similarities. 3) More morphologically complex languages yield lower concept understanding scores and require deeper layers for conceptual reasoning."
}

@misc{liu2025goldmedalsroomdiagnosing,
      title={The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang},
      author={Fenghua Liu and Yulong Chen and Yixuan Liu and Zhujun Jin and Solomon Tsai and Ming Zhong},
      year={2025},
      eprint={2509.00425},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2509.00425},
}

@inproceedings{ginn-palmer-2025-llm,
    title = "{LLM} Dependency Parsing with In-Context Rules",
    author = "Ginn, Michael  and
      Palmer, Alexis",
    editor = "Fei, Hao  and
      Tu, Kewei  and
      Zhang, Yuhui  and
      Hu, Xiang  and
      Han, Wenjuan  and
      Jia, Zixia  and
      Zheng, Zilong  and
      Cao, Yixin  and
      Zhang, Meishan  and
      Lu, Wei  and
      Siddharth, N.  and
      {\O}vrelid, Lilja  and
      Xue, Nianwen  and
      Zhang, Yue",
    booktitle = "Proceedings of the 1st Joint Workshop on Large Language Models and Structure Modeling (XLLM 2025)",
    month = aug,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.xllm-1.17/",
    doi = "10.18653/v1/2025.xllm-1.17",
    pages = "186--196",
    ISBN = "979-8-89176-286-2",
    abstract = "We study whether incorporating rules (in various formats) can aid large language models to perform dependency parsing. We consider a paradigm in which LLMs first produce symbolic rules given fully labeled examples, and the rules are then provided in a subsequent call that performs the actual parsing. In addition, we experiment with providing human-created annotation guidelines in-context to the LLMs. We test on eight low-resource languages from Universal Dependencies, finding that while both methods for rule incorporation improve zero-shot performance, the benefit disappears with a few labeled in-context examples."
}

@inproceedings{pedrotti-etal-2025-humans,
    title = "How Humans and {LLM}s Organize Conceptual Knowledge: Exploring Subordinate Categories in {I}talian",
    author = "Pedrotti, Andrea  and
      Rambelli, Giulia  and
      Villani, Caterina  and
      Bolognesi, Marianna",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.224/",
    doi = "10.18653/v1/2025.acl-long.224",
    pages = "4464--4482",
    ISBN = "979-8-89176-251-0",
    abstract = "People can categorize the same entity at multiple taxonomic levels, such as basic (bear), superordinate (animal), and subordinate (grizzly bear). While prior research has focused on basic-level categories, this study is the first attempt to examine the organization of categories by analyzing exemplars produced at the subordinate level. We present a new Italian psycholinguistic dataset of human-generated exemplars for 187 concrete words. We then leverage these data to evaluate whether textual and vision LLMs produce meaningful exemplars that align with human category organization across three key tasks: exemplar generation, category induction, and typicality judgment. Our findings show a low alignment between humans and LLMs, consistent with previous studies. However, their performance varies notably across different semantic domains. Ultimately, this study highlights both the promises and the constraints of using AI-generated exemplars to support psychological and linguistic research."
}

@inproceedings{zhang-etal-2025-read,
    title = "Read it in Two Steps: Translating Extremely Low-Resource Languages with Code-Augmented Grammar Books",
    author = "Zhang, Chen  and
      Lin, Jiuheng  and
      Liu, Xiao  and
      Zhang, Zekai  and
      Feng, Yansong",
    editor = "Che, Wanxiang  and
      Nabende, Joyce  and
      Shutova, Ekaterina  and
      Pilehvar, Mohammad Taher",
    booktitle = "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2025",
    address = "Vienna, Austria",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.acl-long.202/",
    doi = "10.18653/v1/2025.acl-long.202",
    pages = "3977--3997",
    ISBN = "979-8-89176-251-0",
    abstract = "While large language models (LLMs) have shown promise in translating extremely low-resource languages using resources like dictionaries, the effectiveness of grammar books remains debated. This paper investigates the role of grammar books in translating extremely low-resource languages by decomposing it into two key steps: grammar rule retrieval and application. To facilitate the study, we introduce ZhuangRules, a modularized dataset of grammar rules and their corresponding test sentences. Our analysis reveals that rule retrieval constitutes a primary bottleneck in grammar-based translation. Moreover, although LLMs can apply simple rules for translation when explicitly provided, they encounter difficulties in handling more complex rules. To address these challenges, we propose representing grammar rules as code functions, considering their similarities in structure and the benefit of code in facilitating LLM reasoning. Our experiments show that using code rules significantly boosts both rule retrieval and application, ultimately resulting in a 13.1{\%} BLEU improvement in translation."
}

@inproceedings{cheng-amiri-2025-linguistic,
    title = "Linguistic Blind Spots of Large Language Models",
    author = "Cheng, Jiali  and
      Amiri, Hadi",
    editor = "Kuribayashi, Tatsuki  and
      Rambelli, Giulia  and
      Takmaz, Ece  and
      Wicke, Philipp  and
      Li, Jixing  and
      Oh, Byung-Doh",
    booktitle = "Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics",
    month = may,
    year = "2025",
    address = "Albuquerque, New Mexico, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.cmcl-1.3/",
    doi = "10.18653/v1/2025.cmcl-1.3",
    pages = "1--17",
    ISBN = "979-8-89176-227-5",
    abstract = "Large language models (LLMs) serve as the foundation of numerous AI applications today. However, despite their remarkable proficiency in generating coherent text, questions linger regarding their ability in performing fine-grained linguistic annotation tasks, such as detecting nouns or verbs, or identifying more complex syntactic structures like clauses or T-units in input texts. These tasks require precise syntactic and semantic understanding of input text, and when LLMs underperform on specific linguistic structures, it raises concerns about their reliability for detailed linguistic analysis and whether their (even correct) outputs truly reflect an understanding of the inputs. In this paper, we empirically study recent LLMs performance across fine-grained linguistic annotation tasks. Through a series of experiments, we find that recent LLMs show limited efficacy in addressing linguistic queries and often struggle with linguistically complex inputs. We show that the most capable LLM (Llama3-70b) makes notable errors in detecting linguistic structures, such as misidentifying embedded clauses, failing to recognize verb phrases, and confusing complex nominals with clauses. Our study provides valuable insights to inform future endeavors in LLM design and development."
}

@inproceedings{wilson-13,
	title = {Toward automatic processing of {E}nglish metalanguage},
	url = {https://www.aclweb.org/anthology/I13-1091},
	booktitle = {Proc. of {IJCNLP}},
	author = {Wilson, Shomir},
	year = {2013}
},

@inproceedings{sahin-20,
	title = {{PuzzLing} {M}achines: a challenge on learning from small data},
	url = {https://www.aclweb.org/anthology/2020.acl-main.115},
	booktitle = {Proc. of {ACL}},
	author = {≈ûahin, G√∂zde G√ºl and Kementchedjhieva, Yova and Rust, Phillip and Gurevych, Iryna},
	year = {2020}
},

@inproceedings{wilson-12,
	title = {The creation of a corpus of {E}nglish metalanguage},
	url = {https://aclanthology.org/P12-1067},
	booktitle = {Proc. of {ACL}},
	author = {Wilson, Shomir},
	year = {2012}
},

@inproceedings{wilson-10,
	title = {Distinguishing use and mention in natural language},
	url = {https://aclanthology.org/N10-3006},
	booktitle = {Proc. of the {NAACL} {HLT} 2010 Student Research Workshop},
	author = {Wilson, Shomir},
	year = {2010}
},

@article{rozner-21,
	title = {Decrypting cryptic crosswords: semantically complex wordplay puzzles as a target for {NLP}},
	url = {https://arxiv.org/abs/2104.08620v3},
	author = {Rozner, Joshua and Potts, Christopher and Mahowald, Kyle},
	month = apr,
	year = {2021}
},

@article{berry-05,
	title = {Making the most of metalanguage},
	volume = {14},
	url = {http://www.tandfonline.com/doi/abs/10.1080/09658410508668817},
	number = {1},
	journal = {Language Awareness},
	author = {Berry, Roger},
	month = feb,
	year = {2005},
	pages = {3--20}
},

@inproceedings{barba-21,
	title = {Exemplification modeling: {C}an you give me an example, please?},
	volume = {4},
	url = {https://www.ijcai.org/proceedings/2021/520},
	author = {Barba, Edoardo and Procopio, Luigi and Lacerra, Caterina and Pasini, Tommaso and Navigli, Roberto},
	year = {2021},
	note = {{ISSN}: 1045-0823}
},

@inproceedings{virk-21,
	title = {A deep learning system for automatic extraction of typological linguistic information from descriptive grammars},
	url = {https://aclanthology.org/2021.ranlp-1.166},
	booktitle = {Proc. of {RANLP}},
	author = {Virk, Shafqat Mumtaz and Foster, Daniel and Sheikh Muhammad, Azam and Saleem, Raheela},
	year = {2021}
},

@inproceedings{malm-18,
	title = {{LingFN}: {T}owards a framenet for the linguistics domain},
	booktitle = {Proc. of the {LREC} 2018 Workshop International {FrameNet} Workshop 2018: Multilingual Framenets and Constructicons},
	author = {Malm, Per and Mumtaz Virk, Shafqat and Borin, Lars and Saxena, Anju},
	year = {2018}
},

@inproceedings{virk-20,
	title = {The {DReaM} {C}orpus: {A} multilingual annotated corpus of grammars for the world's languages},
	url = {https://aclanthology.org/2020.lrec-1.110},
	booktitle = {Proc. of {LREC}},
	author = {Virk, Shafqat Mumtaz and Hammarstr√∂m, Harald and Forsberg, Markus and Wichmann, S√∏ren},
	year = {2020}
},

@article{mckeown-21,
	title = {A corpus-based examination of reflexive metadiscourse in majority and dissent opinions of the {U.{S}.} {S}upreme {C}ourt},
	volume = {186},
	url = {https://www.sciencedirect.com/science/article/pii/S0378216621003593},
	journal = {Journal of Pragmatics},
	author = {{McKeown}, Jamie},
	month = dec,
	year = {2021},
	pages = {224--235}
},

@misc{begus-23,
	title = {Large {L}inguistic {M}odels: {A}nalyzing theoretical linguistic abilities of {LLMs}},
	url = {http://arxiv.org/abs/2305.00948},
	publisher = {{arXiv}},
	author = {Begu≈°, Ga≈°per and DƒÖbkowski, Maksymilian and Rhodes, Ryan},
	month = may,
	year = {2023},
	note = {{arXiv}:2305.00948 [cs]}
},

@inproceedings{itzhak-22,
	title = {Models in a spelling bee: {L}anguage models implicitly learn the character composition of tokens},
	url = {https://aclanthology.org/2022.naacl-main.373},
	booktitle = {Proc. of {NAACL-HLT}},
	author = {Itzhak, Itay and Levy, Omer},
	year = {2022}
},

@book{carney-23,
	title = {Linguistics for legal interpretation},
	url = {https://ujonlinepress.uj.ac.za/index.php/ujp/catalog/download/174/495/1656},
	publisher = {{UJ} Press},
	author = {Carney, Terrence R.},
	month = jul,
	year = {2023},
	note = {Publication Title: {UJ} Press
{DOI}: 10.36615/9781776438891}
},

@inproceedings{behzad-23,
	title = {{ELQA}: {A} corpus of metalinguistic questions and answers about {E}nglish},
	url = {https://aclanthology.org/2023.acl-long.113},
	booktitle = {Proc. of {ACL}},
	author = {Behzad, Shabnam and Sakaguchi, Keisuke and Schneider, Nathan and Zeldes, Amir},
	year = {2023}
},

@misc{herrera-24,
	title = {Sparse {L}ogistic {R}egression with {H}igh-order {F}eatures for {A}utomatic {G}rammar {R}ule {E}xtraction from {T}reebanks},
	url = {http://arxiv.org/abs/2403.17534},
	publisher = {{arXiv}},
	author = {Herrera, Santiago and Corro, Caio and Kahane, Sylvain},
	month = mar,
	year = {2024},
	note = {{arXiv}:2403.17534 [cs]
version: 1}
},

@inproceedings{kranzlein-24,
	title = {{CuRIAM}: {C}orpus {R}e {I}nterpretation and {M}etalanguage in {U.{S}.} {S}upreme {C}ourt {O}pinions},
	url = {https://aclanthology.org/2024.lrec-main.379},
	booktitle = {Proc. of {LREC-COLING}},
	author = {Kranzlein, Michael and Schneider, Nathan and Tobia, Kevin},
	editor = {Calzolari, Nicoletta and Kan, {Min-Yen} and Hoste, Veronique and Lenci, Alessandro and Sakti, Sakriani and Xue, Nianwen},
	year = {2024}
},

@inproceedings{almeman-24,
	title = {{WordNet} under scrutiny: {D}ictionary examples in the era of large language models},
	url = {https://aclanthology.org/2024.lrec-main.1538},
	booktitle = {Proc. of {LREC-COLING}},
	author = {Almeman, Fatemah Yousef and Schockaert, Steven and Espinosa Anke, Luis},
	editor = {Calzolari, Nicoletta and Kan, {Min-Yen} and Hoste, Veronique and Lenci, Alessandro and Sakti, Sakriani and Xue, Nianwen},
	year = {2024}
},

@inproceedings{hu-23,
	title = {Prompting is not a substitute for probability measurements in large language models},
	url = {https://aclanthology.org/2023.emnlp-main.306},
	booktitle = {Proc. of {EMNLP}},
	author = {Hu, Jennifer and Levy, Roger},
	editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
	year = {2023}
},

@inproceedings{chaudhary-20,
	title = {Automatic extraction of rules governing morphological agreement},
	url = {https://aclanthology.org/2020.emnlp-main.422},
	booktitle = {Proc. of {EMNLP}},
	author = {Chaudhary, Aditi and Anastasopoulos, Antonios and Pratapa, Adithya and Mortensen, David R. and Sheikh, Zaid and Tsvetkov, Yulia and Neubig, Graham},
	editor = {Webber, Bonnie and Cohn, Trevor and He, Yulan and Liu, Yang},
	year = {2020}
},

@misc{tanzer-24,
	title = {A benchmark for learning to translate a new language from one grammar book},
	url = {http://arxiv.org/abs/2309.16575},
	publisher = {{arXiv}},
	author = {Tanzer, Garrett and Suzgun, Mirac and Visser, Eline and Jurafsky, Dan and {Melas-Kyriazi}, Luke},
	month = feb,
	year = {2024},
	note = {{arXiv}:2309.16575 [cs]}
},

@inproceedings{gajbhiye-24,
	title = {{AMenDeD}: {M}odelling concepts by aligning mentions, definitions and decontextualised embeddings},
	url = {https://aclanthology.org/2024.lrec-main.72},
	booktitle = {Proc. of {LREC-COLING}},
	author = {Gajbhiye, Amit and Bouraoui, Zied and Espinosa Anke, Luis and Schockaert, Steven},
	editor = {Calzolari, Nicoletta and Kan, {Min-Yen} and Hoste, Veronique and Lenci, Alessandro and Sakti, Sakriani and Xue, Nianwen},
	year = {2024}
},

@inproceedings{thrush-24,
	title = {I am a strange dataset: metalinguistic tests for language models},
	url = {https://aclanthology.org/2024.acl-long.482},
	booktitle = {Proc. of {ACL}},
	author = {Thrush, Tristan and Moore, Jared and Monares, Miguel and Potts, Christopher and Kiela, Douwe},
	editor = {Ku, {Lun-Wei} and Martins, Andre and Srikumar, Vivek},
	year = {2024}
},

@article{yang-24,
	title = {Tailored definitions with easy reach: complexity-controllable definition generation},
	url = {https://ieeexplore.ieee.org/abstract/document/10816507},
	journal = {{IEEE} Transactions on Big Data},
	author = {Yang, Liner and Yuan, Jiaxin and Kong, Cunliang and Yu, Jingsi and Chong, Ruining and Liu, Zhenghao and Yang, Erhong},
	year = {2024},
	note = {Conference Name: {IEEE} Transactions on Big Data},
	pages = {1--12}
},

@inproceedings{spencer-25,
	title = {Can {LLMs} help create grammar?: {A}utomating grammar creation for endangered languages with in-context learning},
	url = {https://aclanthology.org/2025.coling-main.681/},
	booktitle = {Proc. of {COLING}},
	author = {Spencer, Piyapath T. and Kongborrirak, Nanthipat},
	editor = {Rambow, Owen and Wanner, Leo and Apidianaki, Marianna and {Al-Khalifa}, Hend and Eugenio, Barbara Di and Schockaert, Steven},
	year = {2025}
},

@inproceedings{chi-24,
	title = {{ModeLing}: a novel dataset for testing linguistic reasoning in language models},
	url = {https://aclanthology.org/2024.sigtyp-1.14/},
	booktitle = {Proc. of the 6th Workshop on Research in Computational Linguistic Typology and Multilingual {NLP}},
	author = {Chi, Nathan and Malchev, Teodor and Kong, Riley and Chi, Ryan and Huang, Lucas and Chi, Ethan and {McCoy}, R. and Radev, Dragomir},
	editor = {Hahn, Michael and Sorokin, Alexey and Kumar, Ritesh and Shcherbakov, Andreas and Otmakhova, Yulia and Yang, Jinrui and Serikov, Oleg and Rani, Priya and Ponti, Edoardo M. and Muradoƒülu, Saliha and Gao, Rena and Cotterell, Ryan and Vylomova, Ekaterina},
	year = {2024}
},

@misc{aycock-24,
	title = {Can {LLMs} {R}eally {L}earn to {T}ranslate a {Low-Resource} {L}anguage from {O}ne {G}rammar {B}ook?},
	url = {http://arxiv.org/abs/2409.19151},
	publisher = {{arXiv}},
	author = {Aycock, Seth and Stap, David and Wu, Di and Monz, Christof and Sima'an, Khalil},
	month = sep,
	year = {2024},
	note = {{arXiv}:2409.19151 [cs]}
}
@inproceedings{behzad-etal-2024-ask,
    title = "To Ask {LLM}s about {E}nglish Grammaticality, Prompt Them in a Different Language",
    author = "Behzad, Shabnam  and
      Zeldes, Amir  and
      Schneider, Nathan",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.findings-emnlp.916/",
    doi = "10.18653/v1/2024.findings-emnlp.916",
    pages = "15622--15634",
    abstract = "In addition to asking questions about facts in the world, some internet users{---}in particular, second language learners{---}ask questions about language itself. Depending on their proficiency level and audience, they may pose these questions in an L1 (first language) or an L2 (second language). We investigate how multilingual LLMs perform at crosslingual metalinguistic question answering. Focusing on binary questions about sentence grammaticality constructed from error-annotated learner corpora, we prompt three LLMs (Aya, Llama, and GPT) in multiple languages, including English, German, Korean, Russian, and Ukrainian. Our study reveals that the language of the prompt can significantly affect model performance, and despite English being the dominant training language for all three models, prompting in a different language with questions about English often yields better results."
}
